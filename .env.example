# === PROVIDER LLM ===
# Choisir entre "ollama" (local), "mistral" (API cloud) ou "openai" (API cloud)
LLM_PROVIDER=ollama

# Temperature du modele (0.0 = deterministe, 1.0 = creatif)
MODEL_TEMPERATURE=0.7

# === PROVIDER EMBEDDINGS (optionnel) ===
# Permet d'utiliser un modele d'embedding d'un provider different du LLM
# Valeurs possibles: ollama, mistral, openai, huggingface
# Si non defini, utilise la valeur de LLM_PROVIDER
# EMBEDDING_PROVIDER=huggingface

# === CONFIGURATION OLLAMA (si LLM_PROVIDER=ollama) ===
OLLAMA_MODEL=phi3:mini
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# === CONFIGURATION MISTRAL (si LLM_PROVIDER=mistral) ===
# Obtenez votre cle API sur: https://console.mistral.ai/
MISTRAL_API_KEY=votre_cle_api_mistral
MISTRAL_MODEL=mistral-small-latest
MISTRAL_EMBEDDING_MODEL=mistral-embed

# === CONFIGURATION OPENAI (si LLM_PROVIDER=openai) ===
# Obtenez votre cle API sur: https://platform.openai.com/api-keys
OPENAI_API_KEY=votre_cle_api_openai
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# === CONFIGURATION HUGGINGFACE EMBEDDINGS (si EMBEDDING_PROVIDER=huggingface) ===
# Modeles locaux via sentence-transformers, pas besoin de cle API
HUGGINGFACE_EMBEDDING_MODEL=intfloat/multilingual-e5-large

# === CONFIGURATION GOOGLE CLOUD STORAGE (upload de documents PDF) ===
# Nom du bucket GCS (obligatoire pour l'upload)
GCS_BUCKET_NAME=votre-bucket-name
# ID du projet GCP
GCS_PROJECT_ID=votre-project-id
# Cle JSON du service account (coller le contenu du fichier JSON)
GCS_SERVICE_ACCOUNT_KEY={}
# MAX_UPLOAD_SIZE_BYTES=10485760

# === CONFIGURATION REDIS (API + Worker) ===
REDIS_URL=redis://localhost:6379

# === CONFIGURATION POSTGRESQL (memoire long-terme) ===
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=agent_memory
POSTGRES_USER=postgres
POSTGRES_PASSWORD=votre_mot_de_passe

# Alternative: Connection string complete (prioritaire si definie)
# DATABASE_URL=postgresql://user:password@host:port/database

# Prompt système pour l'agent de service client
SYSTEM_PROMPT=Vous êtes un agent de service client français professionnel et courtois. Votre rôle est d'aider les clients avec leurs questions et préoccupations. Soyez toujours poli, empathique et orienté solution. Maintenez le contexte de la conversation et fournissez des réponses claires et concises en français.

# Optionnel: Prompt système spécifique pour l'agent RAG
# SYSTEM_PROMPT_RAG=Vous êtes un agent de service client français professionnel et courtois. Votre rôle est d'aider les clients avec leurs questions et préoccupations. Vous avez accès à une base de documents via l'outil 'search_documents'. Utilisez cet outil pour rechercher des informations pertinentes lorsque les clients posent des questions sur les produits, services ou politiques. Soyez toujours poli, empathique et orienté solution. Fournissez des réponses claires basées sur les documents disponibles. Si l'information n'est pas disponible dans les documents, indiquez-le poliment au client.

# Optionnel: LangSmith pour le tracing
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=votre-clé-langsmith
